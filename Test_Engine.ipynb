{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Note : use Colab python environemnt to run this code , because if you want to use it locally , you might face trouble due to configuration setting of pytorch , make sure all the necessaary files of pretrained model is saved in your specifed directory , all the below listed files are necessary to use pretrained model which are as follow : **Vocab.txt , training_args.bin, tokenizer_config.json, special_tokens, model.safetensors,config.json**"
      ],
      "metadata": {
        "id": "hgaRBv2KgVLa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9FM-YqvcNuq",
        "outputId": "584b97ce-ef2b-4e94-c62d-59be7b8afbc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Db1LmaAsc5t8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path where Trained model is saved"
      ],
      "metadata": {
        "id": "xlbRzLjVdokv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = \"/content/drive/MyDrive/ut\""
      ],
      "metadata": {
        "id": "KTNAjyd_cRxz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Pretrained model to predict call reason for given transcripts"
      ],
      "metadata": {
        "id": "6aptcsRidtgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained(model_save_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_save_path)"
      ],
      "metadata": {
        "id": "CdHcC37Icf99"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "labels = ['Voluntary Cancel', 'Booking', 'IRROPS', 'Upgrade', 'Seating',\n",
        "       'Mileage Plus', 'Checkout', 'Voluntary Change', 'Post Flight',\n",
        "       'Check In', 'Other Topics', 'Communications', 'Schedule Change',\n",
        "       'Products and Services', 'Digital Support', 'Disability',\n",
        "       'Unaccompanied Minor', 'Baggage', 'Traveler Updates', 'ETC']"
      ],
      "metadata": {
        "id": "8WhxpxfldNpC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)"
      ],
      "metadata": {
        "id": "j1p_YK1BdIFI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample Test block to check prediction capabilities of model**"
      ],
      "metadata": {
        "id": "cj1PA7Zsd-DQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run next cell toh this text to use the trained model , when you run next cell it ask for the input , input the call transcript , after few seconds you get your call reason for the given transcipt"
      ],
      "metadata": {
        "id": "hZkBcGhefaMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_texts = input()  # Example transcript\n",
        "\n",
        "# Tokenize the new text\n",
        "new_encodings = tokenizer(new_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Predict\n",
        "outputs = model(**new_encodings)\n",
        "predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "# Convert prediction to label\n",
        "predicted_reason = label_encoder.inverse_transform(predictions.detach().numpy())\n",
        "\n",
        "print(predicted_reason)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysjnAoDLci1g",
        "outputId": "0db0bc35-e82f-46b1-8c85-ee9346fbbbc7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Agent: Thank you for calling United Airlines customer service, my name is Steve. How may I help you today?  Customer: Hi, I'm calling to complain about my recent flight. The service was terrible.  Agent: I'm sorry to hear about that. Could you please provide your reservation details so I can pull up your flight information?  Customer: Sure, the flight was from New York to LA last Thursday. Reservation name is John Smith.  Agent: Let me take a look here...okay, I've found your reservation Mr. Smith. What issues did you experience on your flight?  Customer: Well for starters, your airline lost my luggage! I've been waiting over a week and still don't have it. On top of that, the plane was delayed for over 3 hours and we didn't get any explanation or compensation. Then during the flight, the food they served was disgusting and inedible. This was an awful experience from start to finish.   Agent: I apologize for the problems you encountered, that does sound like a very frustrating travel experience. Let me see what I can do to help make this right. In regards to your lost luggage, I'll put in a claim for you right now. It can take some time but lost items do usually get reunited with their owners. On the flight delay, unfortunately we don't provide compensations for delays under 4 hours as per department of transportation guidelines. However, I can offer you a $100 travel voucher for the inconvenience. As for the meal, that's unacceptable and I'll pass that feedback along. Is there anything else I can assist with today?  Customer: Honestly I'm just really disappointed. I've been a loyal United customer for over 10 years and this is the worst service I've ever received. That voucher isn't going to make up for the hassle and time wasted with this trip. You guys really dropped the ball.   Agent: You're right, sir, we definitely fell short of providing you a positive travel experience. I understand your frustration. Umm, let me see if there's anything else I can do. *typing noises* How does a $250 voucher and 10,000 bonus miles sound? I want to sincerely apologize again for all the problems. I know it doesn't make up for it completely but hopefully this shows our commitment to taking care of loyal customers.  Customer: *sighs* I guess that's a bit better. But I better not have any other issues if I book another flight with you guys. And you need to get my bag back to me asap.  Agent: You have my word we'll do everything possible to ensure any future travel with us is smooth. I'll mark your luggage as high priority so it gets expedited. If there are any other delays or problems, please don't hesitate to call back and ask for me directly. We appreciate your business over the years and want to regain your trust. Thank you for your patience today.  Customer: All right, thanks I guess. *hangs up phone angrily*   Agent: You're very welcome sir, and thank you for flying United. Have a good rest of your day. *Call disconnects*  How was that? I tried to generate a realistic conversation between an annoyed customer and patient agent within the given call time frame, word count, and other variables provided. Please let me know if you would like me to modify or expand on anything.\n",
            "['IRROPS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction Engine**"
      ],
      "metadata": {
        "id": "MEh9l5CUek60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : for 5157 no of transcripts it takes 2.5 hours to predict all the call reason for all 5157 transcipt , carefull before running the below cells"
      ],
      "metadata": {
        "id": "tpHpQ06Se5Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/drive/MyDrive/ut2/merged_output.xlsx\") # put that files taht contain transcripts"
      ],
      "metadata": {
        "id": "ct7TT3Jlcqkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcripts = df['call_transcript'].tolist()"
      ],
      "metadata": {
        "id": "TJjaTRyCe1tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the Excel has 'call_id' and 'call_transcript' columns\n",
        "call_ids = df['call_id'].tolist()\n",
        "call_transcripts = df['call_transcript'].tolist()\n",
        "\n",
        "\n",
        "class_labels = ['Voluntary Cancel', 'Booking', 'IRROPS', 'Upgrade', 'Seating',\n",
        "       'Mileage Plus', 'Checkout', 'Voluntary Change', 'Post Flight',\n",
        "       'Check In', 'Other Topics', 'Communications', 'Schedule Change',\n",
        "       'Products and Services', 'Digital Support', 'Disability',\n",
        "       'Unaccompanied Minor', 'Baggage', 'Traveler Updates', 'ETC']\n",
        "\n",
        "predicted_reasons = []\n",
        "\n",
        "# Loop through the transcripts and predict the reason for each\n",
        "for transcript in call_transcripts:\n",
        "    # Tokenize the transcript\n",
        "    new_encodings = tokenizer([transcript], truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "    # Get model predictions\n",
        "    outputs = model(**new_encodings)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "    # Map the prediction to the corresponding label\n",
        "    predicted_reason = class_labels[predictions.item()]  # Get the label from the list\n",
        "    predicted_reasons.append(predicted_reason)\n",
        "\n",
        "# Add the predicted reasons to the DataFrame\n",
        "df['predicted_reason'] = predicted_reasons\n",
        "\n"
      ],
      "metadata": {
        "id": "Dnxe4Xmee4BJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}